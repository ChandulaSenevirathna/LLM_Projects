{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9555b7",
   "metadata": {},
   "source": [
    "### Conversational AI (Chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca49359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba75fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91bcd663",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e98e7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01bb00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_gemini(prompt):\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.0-flash\",  # or \"gemini-1.5-pro\"\n",
    "        system_instruction=system_message\n",
    "    )\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1477cb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=message_gemini,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs=[gr.Textbox(label=\"Response:\", lines=8)],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf5f15",
   "metadata": {},
   "source": [
    "### Streaming Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf6c9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_message = \"You are a helpful assistant that responds in markdown\"  # Optional system instruction\n",
    "\n",
    "def stream_gemini(prompt):\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.0-flash\",\n",
    "        system_instruction=system_message\n",
    "    )\n",
    "\n",
    "    stream = model.generate_content(prompt, stream=True)\n",
    "\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.text:\n",
    "            result += chunk.text\n",
    "            yield result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3074b168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, imagine regular computers (the ones we use every day) like light switches. Each switch can be either on (1) or off (0). These are called bits, and they're the fundamental building blocks of how computers store and process information.\n",
       "\n",
       "Quantum computers, on the other hand, are like dimmer switches. They can be on (1), off (0), **or** somewhere in between (both 1 and 0 *at the same time*).  This \"somewhere in between\" state is called **superposition**.\n",
       "\n",
       "Here's a breakdown of the key ideas:\n",
       "\n",
       "*   **Qubits:** Instead of bits, quantum computers use **qubits**.  A qubit can be 0, 1, or a *superposition* of both 0 and 1. Think of it like a spinning coin - it's neither heads nor tails until it lands.\n",
       "\n",
       "*   **Superposition:** This allows a qubit to represent multiple possibilities simultaneously.  Instead of exploring one possibility at a time (like a regular computer), a quantum computer can explore many possibilities at once.  This gives them incredible power for certain kinds of problems.\n",
       "\n",
       "*   **Entanglement:**  This is where things get really weird. Imagine two of our spinning coins that are linked together in a special way. If you look at one and it lands on heads, you instantly know the other one is tails, even if they're miles apart.  That's kind of like entanglement. Entangled qubits are linked, so the state of one affects the state of the other, no matter the distance. This allows qubits to work together and solve problems in ways classical computers can't.\n",
       "\n",
       "*   **Measurement:** When you finally need an answer from a quantum computer, you \"measure\" the qubits.  This forces them to \"choose\" a state (either 0 or 1), and you get the result. However, the act of measuring destroys the superposition and entanglement.\n",
       "\n",
       "**Why is this useful?**\n",
       "\n",
       "Quantum computers are not going to replace your laptop anytime soon. They're really good at solving specific types of problems that are incredibly difficult for regular computers, such as:\n",
       "\n",
       "*   **Drug Discovery:** Simulating molecules to design new medicines.\n",
       "*   **Materials Science:** Discovering new materials with specific properties.\n",
       "*   **Cryptography:** Breaking existing encryption and creating new, more secure methods.\n",
       "*   **Optimization:** Finding the best solution to complex problems, like optimizing delivery routes or financial portfolios.\n",
       "*   **Artificial Intelligence:** Training AI models faster and more efficiently.\n",
       "\n",
       "**In summary:**\n",
       "\n",
       "Quantum computers use qubits that can be in a superposition of 0 and 1, and they can be entangled with each other.  This allows them to explore many possibilities at once and solve certain complex problems much faster than classical computers.  They are not a replacement for your current computer, but a specialized tool for tackling specific scientific and technological challenges.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for partial in stream_gemini(\"Explain quantum computing in simple terms.\"):\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(partial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5370e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = gr.Interface(\n",
    "    fn=stream_gemini,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs=gr.Markdown(),\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70510c67",
   "metadata": {},
   "source": [
    "### Chat Bot With History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "311de565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gemini_with_history(message, history):\n",
    "        \n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-2.0-flash\",\n",
    "        system_instruction=system_message\n",
    "    )\n",
    "    \n",
    "    prompt = \"\"\n",
    "    for user_msg, bot_msg in history:\n",
    "        prompt += f\"User: {user_msg}\\nAssistant: {bot_msg}\\n\"\n",
    "    prompt += f\"User: {message}\\nAssistant:\"\n",
    "\n",
    "    stream = model.generate_content(prompt, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.text:\n",
    "            response += chunk.text\n",
    "            yield history + [(message, response)], \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a6d9719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chandula\\AppData\\Local\\Temp\\ipykernel_15184\\1344445376.py:7: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Conversation\", show_copy_button=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clear_chat():\n",
    "    return [], \"\"\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as view:\n",
    "    gr.Markdown(\"## ðŸ’¬ Chat Bot with History\")\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"Conversation\", show_copy_button=True)\n",
    "    msg = gr.Textbox(label=\"Your message:\", lines=2, placeholder=\"Type your message here...\")\n",
    "\n",
    "    with gr.Row():\n",
    "        send_btn = gr.Button(\"Send\")\n",
    "        clear_btn = gr.Button(\"Clear Chat\")\n",
    "\n",
    "    msg.submit(stream_gemini_with_history, inputs=[msg, chatbot], outputs=[chatbot, msg])\n",
    "    send_btn.click(stream_gemini_with_history, inputs=[msg, chatbot], outputs=[chatbot, msg])\n",
    "\n",
    "    clear_btn.click(clear_chat, outputs=[chatbot, msg])\n",
    "\n",
    "view.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
